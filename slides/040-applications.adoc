[%auto-animate.is-full]
== Gestion applicative

Un control plane haute disponibilité, mais un seul pod pour son application, ça n'a pas grand intérêt...

[.notes]
****
Maintenant que notre cluster est résilient sur deux régions, il est temps de s'intéresser aux applications qui tournent dessus. impact sur applications. partir de solution naive vers une proposition de solution
****

[%notitle]
=== Par défaut

plantuml::diagrams/040-deploy-without-anti-affinity.puml[format=svg,id=040-without-anti-affinity]

[.notes]
****
Pas de garantie de placement du pod (scheduler)
****

[%notitle]
=== Gestion des régions

plantuml::diagrams/040-deploy-with-anti-affinity.puml[format=svg,id=040-with-anti-affinity,height=650px]

=== Anti-affinité

[source%linenums,yaml,highlight=6-9]
----
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - topologyKey: topology.kubernetes.io/region
  containers: # [...]
----

[.notes]
****
Cas d'usage : pour répartir les pods sur les deux régions

Insister sur le fait que ici, c'est obligatoire et que le pod ne démarrera pas si scheduler non valide
****

=== Affinité

[source%linenums,yaml,highlight=6-8|10-17]
----
apiVersion: v1
kind: Pod
metadata:
  name: my-bdd
spec:
  affinity:
    podAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - my-redis
          topologyKey: topology.kubernetes.io/region
  containers: # [...]
----

[.notes]
****
Cas d'usage : latence faible, pour regrouper par exemple bdd et cache

Montrer que scheduler peut ignorer ici, car c'est une préférence
****

=== Et pour du stateful ?

plantuml::diagrams/040-storage-presentation.puml[format=svg,id=040-storage-presentation,height=500]

[.notes]
****
= Stocker des données, bdd, faire des statefulset ne suffit pas, il faut gérer réplication données entre les régions.

Parfois, nous dépendons d'opérateurs k8s, qui ont parfois leurs particularités.

Pourrait être simple, si Stockage répliqué, mais ce n'est pas le cas du client = 2 zones stockage par région, mais pas de réplication entre les régions > il faut gérer la réplication des données au niveau applicatif. Du coup, nos PVC ne sont pas répliqués entre les régions et il faut gérer cela au niveau applicatif.
****

== PostgreSQL

https://cloudnative-pg.io/

[source%linenums,yaml,highlight=2-3|7-11]
----
---
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: database
spec:
  affinity:
    enablePodAntiAffinity: true
    podAntiAffinityType: required # or preferred
    topologyKey: topology.kubernetes.io/region
  instances: 2
----

[.notes]
****
Focus sur CRD custom

L'opérateur fait le travail, pour peu que l'on configure l'anti-affinité entre les régions

Configuration de la CRD pour indiquer que l'on répartit les pods sur les deux régions et on indique que l'anti-affinité est obligatoire selon le nombre d'instances demandées.

prefered, attention, nos instances pg peuvent se retrouver sur la même région
****

[%notitle]
=== ⚠️ Postgres

[.column]
--
[caption=,link=https://www.redhat.com/en/blog/build-your-kubernetes-operator-with-the-right-tool]
.⚠️
image::operator.webp[]
--

[.notes]
****
Anecdote : si API K8S KO, l'opérateur ne peut plus mettre à jour le service pour élire le nouveau principal. En effet, l'opérateur cherche à mettre à jour un service pour indiquer que le pod postgres restant doit devenir le pod principal et tente de mettre à jour le service Kubernetes correspondant. cependant, si pas d'API k8s... Pas de mise à jour du service !
****

[.columns]
== Kafka

[.column]
--
[link=https://fr.wikipedia.org/wiki/Fichier:Apache_Kafka_logo.svg]
image::kafka.svg[]
--

[.column]
--
.https://strimzi.io/
[link=https://strimzi.io/,caption=]
image::strimzi.png[]
--

[.notes]
****
Kafka est un système de file de messages distribué

https://kafka.apache.org/documentation/#gettingStarted

On déploie à l'aide d'un opérateur Strimzi, qui va nous permettre de gérer la réplication entre les régions.

Cependant, il y a 2 cas de figures

https://github.com/emeraldhieu/raft-consensus
****

[.small-title]
=== Si vous êtes à la bourre... ⌚

plantuml::diagrams/040-kafka-zookeeper.puml[format=svg,id=040-kafka-zookeeper,height=650px]

[.notes]
****
Si vous êtes encore sous zookeeper, et bien déjà, sachez que vous ne pouvez plus mettre à jour vers de nouvelles versions, car Kraft est le mode par défaut pour les éléctions de leader.

**⚠️ Depuis Kafka 4.0, le mode de fonctionnement par défaut est Kraft (Kafka Raft). Il n'y a plus de fonctionnement possible avec Zookeeper ⚠️**

Pourquoi on a besoin de Zookeeper ? Parce que c'est lui qui gère les élections de leader entre les brokers. En effet, si on perd une région, il faut élire un nouveau leader, et pour cela, il faut que Zookeeper soit accessible. Ainsi, la consommation/production dans les topics n'est possible que si Zookeeper est disponible, car c'est lui qui indiquera au broker quelle est la partition leader.

https://kafka.apache.org/documentation/

Comment on fait dans ce cas ? On doit garantir la stabilité de notre zookeeper, et dans ce cas, s'assurer qu'il soit répartir sur les 2 régions, et en cas de crash de la région ou N/2-1, rétablir manuellement l'accès au service, via provisionnement d'un nouveau node zookeeper.
****

[.small-title]
=== Et si je suis à jour ?

plantuml::diagrams/040-kafka.puml[format=svg,id=040-kafka,height=650px]

[.notes]
****
Si vous avez déjà migré sur Kraft (ça vous rappelle quelques choses ?), vous ne devriez rien avoir à faire, si ce n'est faire attention à la configuration de vos topics, afin de s'assurer de la bonne réplications de vos données. En effet, l'election est géré par les brokers eux-mêmes et non plus par Zookeeper. Il n'y a donc plus de dépendance à Zookeeper pour l'élection des leaders, mais il faut tout de même s'assurer que les brokers sont bien répartis sur les deux régions.

Cependant, attention à la configuration applicative de vos topics, sinon, vous pourriez avoir un kafka certes disponible, mais les données de vos topics ne seront pas répliquées entre les deux régions.
****

=== ⚠️ Pensez à vos topics !

[source,yaml%linenums,highlight=7-11]
----
---
kind: Kafka
metadata:
  name: kafka
spec:
  kafka:
    rack:
      topologyKey: topology.kubernetes.io/region
    config:
      replica.selector.class: org.apache.kafka.common.replica.RackAwareReplicaSelector
      min.insync.replicas: 2
----

[.notes]
****
Activer la sélection basée sur les racks : RackAwareReplicaSelector dans replica.selector.class. Cela garantit que Kafka essaiera de placer les réplicas sur des racks (ou régions) différents.

Même problématique que API K8S = 2/1 ou 3/0 ? Pas possible de faire du 3/0, si on perd la mauvaise région, on perd tout. On va donc préférer avoir 2 kafka sur chaque région, et assurer une réplication minimum de 2 pour chaque message dans les topics, afin de s'assurer d'avoir une copie du message dans chaque région.


https://github.com/orgs/strimzi/discussions/11012
****

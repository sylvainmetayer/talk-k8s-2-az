[%auto-animate.is-full]
== Mono Control Plane

[.column]
--
plantuml::diagrams/030-mono-cp.puml[format=svg,id=030-mono-cp]
--

[.notes]
****
mono CP. 1 control plane pour notre cluster, 1 vm CP sur un des 2 sites. Redondacne à la VMWare (VRA ??) snapshot de la VM, on remonte de l'autre côté

Présenter 3/0, sans parler d'ETCD RAFt, et besoin de CP sur les 2 côtés pour API haute dispo car opérateur qui met à jour services / pas de bascule auto VMWare car pas licence pour mon projet et aç créé problème supplémentaire, car mes opérateurs ne peuvent pas metre à jour les services / ...
****

[%auto-animate.is-full.columns]
== Multi Control Plane

[.column.is-four-fifths]
--
plantuml::diagrams/030-multi-cp.puml[format=svg,id=030-multi-cp]
--

[.column]
--
image::openshift-logo.svg[width=100]
--


[.notes]
****
En théorie, la mécanique reste la même : on bascule nos 3 control planes sur la région B. On a donc 3 control planes sur la région B.

==> Attention, moi j'ai besoin d'avoir l'API dispo en continu, j'ai des opérateurs qui dépendent de l'API k8s !

Bon, bah on va faire du 2/1, ça doit être possible ? Qu'est-ce qu'il y a derrière ce fameux control plane qui nous en empêche de faire ça ? Voyons ça !
****

== Control Plane

[link=https://kubernetes.io/docs/concepts/overview/components/]
image::kubernetes-components.svg[]

[.notes]
****
TODO Schéma des composants d'un control plane, avec les différents composants (kube-apiserver, kube-controller-manager, kube-scheduler, etcd) et comment ils interagissent entre eux.

On va maintenant s'intéresser à la partie qui nécessite de la persistence de données, ETCD
****

[%notitle]
=== etcd

[link=https://etcd.io/]
image::etcd-horizontal-color.svg[]

image::etcd-xkcd-2347.webp[]

[.notes]
****
Base clé-valeurs distribuée, créé par CoreOS en 2013, puis passé dans le giron de la CNCF depuis 2018.
Composant du cœur de k8s
****

=== Raft consensus algorithm

[link=https://raft.github.io]
image::raft-sticker.svg[]

[.notes]
****
TODO Ajouter un schéma ou 2 ? (GIF fonctionnement)

Algo de consensus implémenté dans etcd.
Illustration : raftscope (en JS) ou schéma ?
Sinon une note sur la mécanique et explication orale uniquement.
- algo pour implémenter la réplication de logs
- le système évolue/avance tant que la majorité des nœuds sont disponibles
- model d’erreur : fail-stop, delayed/lost messages
- conçu pour la compréhensibilité
****

=== Follower failure

[.notes]
****
TODO Nico fusionner les slides pour faire un schéma récapitulatif des scénarios.

https://etcd.io/docs/v3.5/op-guide/failures/#minor-followers-failure
****

=== Leader failure

[.notes]
****
https://etcd.io/docs/v3.5/op-guide/failures/#minor-followers-failure
****

=== Majority failure

[.notes]
****
https://etcd.io/docs/v3.5/op-guide/failures/#majority-failure
****

=== Network partition

TODO Nico fusionner les slides pour faire un schéma récapitulatif des scénarios. (voir diagrams/030-etcd-haute-dispo.mmd)

[.notes]
****
## Résumé des Modes de Défaillance dans etcd

### Partition Réseau
- **Description** : Une partition réseau divise un cluster etcd en deux parties : une majorité et une minorité de membres.
- **Disponibilité** : La partie majoritaire reste disponible, tandis que la partie minoritaire devient indisponible.
- **Absence de "Split-brain"** : etcd évite le phénomène de "split-brain" car les membres du cluster sont explicitement ajoutés ou retirés avec l'approbation de la majorité actuelle. => TODO Définition split brain (slide à part ?)

### Conséquences Selon la Position du Leader
- **Leader dans la Majorité** : Si le leader est du côté majoritaire, la défaillance est perçue comme une défaillance des followers minoritaires.
- **Leader dans la Minorité** : Si le leader est du côté minoritaire, il se retire, et un nouveau leader est élu par la majorité.

### Récupération Après la Partition
- **Reconnaissance Automatique** : Une fois la partition réseau résolue, la minorité reconnaît automatiquement le leader de la majorité et récupère son état.
https://etcd.io/docs/v3.5/op-guide/failures/#network-partition
****

=== Failure during bootstrapping

[.notes]
****
https://etcd.io/docs/v3.5/op-guide/failures/#failure-during-bootstrapping
****

== Recovery

[.qrcode.five]
qrcode::https://docs.rke2.io/datastore/backup_restore[format="png", xdim=4]

[.qrcode.right.five]
qrcode::https://etcd.io/docs/v3.5/op-guide/recovery/[format="png", xdim=4]

plantuml::diagrams/030-recovery.puml[format=svg,id=030-recovery]

[.notes]
****
Recovery : ETCD crash, comment on récupère ? Snapshot d'une dernière VM / soit backup ETCD (avec recréation d'un nouveau quorum mono et intégration des autres membres) => Schéma !

On précise que l'on doit supprimer les données de l'ETCD avant de le réintégrer dans le cluster, sinon, il ne pourra pas se réintégrer au quorum en tant que nouveau membre
****
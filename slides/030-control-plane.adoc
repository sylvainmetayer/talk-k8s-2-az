[%auto-animate.is-full.no-transition]
== Mono Control Plane

plantuml::diagrams/030-mono-cp-1.puml[format=svg,id=030-mono-cp-1]

[.notes]
****
mono CP. 1 control plane pour notre cluster, 1 vm CP sur un des 2 sites. Redondacne à la VMWare (VRA ??) snapshot de la VM, on remonte de l'autre côté

Présenter 3/0, sans parler d'ETCD RAFt, et besoin de CP sur les 2 côtés pour API haute dispo car opérateur qui met à jour services / pas de bascule auto VMWare car pas licence pour mon projet et aç créé problème supplémentaire, car mes opérateurs ne peuvent pas metre à jour les services / ...
****

[%auto-animate.is-full.no-transition]
=== Mono Control Plane

plantuml::diagrams/030-mono-cp-2.puml[format=svg,id=030-mono-cp-2]

[.notes]
****
mono CP. 1 control plane pour notre cluster, 1 vm CP sur un des 2 sites. Redondacne à la VMWare (VRA ??) snapshot de la VM, on remonte de l'autre côté

Présenter 3/0, sans parler d'ETCD RAFt, et besoin de CP sur les 2 côtés pour API haute dispo car opérateur qui met à jour services / pas de bascule auto VMWare car pas licence pour mon projet et aç créé problème supplémentaire, car mes opérateurs ne peuvent pas metre à jour les services / ...
****

[%auto-animate.is-full.no-transition]
=== Mono Control Plane

plantuml::diagrams/030-mono-cp-3.puml[format=svg,id=030-mono-cp-3]

[.notes]
****
mono CP. 1 control plane pour notre cluster, 1 vm CP sur un des 2 sites. Redondacne à la VMWare (VRA ??) snapshot de la VM, on remonte de l'autre côté

Présenter 3/0, sans parler d'ETCD RAFt, et besoin de CP sur les 2 côtés pour API haute dispo car opérateur qui met à jour services / pas de bascule auto VMWare car pas licence pour mon projet et aç créé problème supplémentaire, car mes opérateurs ne peuvent pas metre à jour les services / ...
****

[%auto-animate.is-full.columns]
== Multi Control Plane

[.column.is-four-fifths]
--
plantuml::diagrams/030-multi-cp.puml[format=svg,id=030-multi-cp]
--

[.column]
--
image::openshift-logo.svg[width=100]
--

[.notes]
****
En théorie, la mécanique reste la même : on bascule nos 3 control planes sur la région B. On a donc 3 control planes sur la région B.

==> Attention, moi j'ai besoin d'avoir l'API disponible en continu, j'ai des opérateurs qui dépendent de l'API k8s ! TODO Jamy

Bon, bah on va faire du 2/1, ça doit être possible ? Qu'est-ce qu'il y a derrière ce fameux control plane qui nous en empêche de faire ça ? Voyons ça !
****

[%notitle]
=== etcd

[link=https://etcd.io/]
image::etcd-horizontal-color.svg[]

image::etcd-xkcd-2347.webp[]

[.notes]
****
Base clé-valeurs distribuée, créé par CoreOS en 2013, puis passé dans le giron de la CNCF depuis 2018.
Composant du cœur de k8s
****

=== Raft consensus algorithm

[link=https://raft.github.io]
image::raft-sticker.svg[]

[.notes]
****
TODO Ajouter un schéma ou 2 ? (GIF fonctionnement)

Algo de consensus implémenté dans etcd.
Illustration : raftscope (en JS) ou schéma ?
Sinon une note sur la mécanique et explication orale uniquement.
- algo pour implémenter la réplication de logs
- le système évolue/avance tant que la majorité des nœuds sont disponibles
- model d’erreur : fail-stop, delayed/lost messages
- conçu pour la compréhensibilité
****

[%notitle,background-iframe="/raftscope"]
=== Démo

[.notes]
****
https://github.com/ongardie/raftscope.git

scénario :
1. Dès qu’un leader est élu, Request pour écrire
2. Stop follower
3. Request
4. Time out pour lancer une nouvelle élection sur follower, puis Request
5. Stop leader - pas d’élection possible
6. Resume followers
7. Request, et Stop leader avant consensus
8. Time out sur un follower, dès élection Request
9. Retour de l’ancien leader : il se met à jour
****

=== Network partition

plantuml::diagrams/030-etcd-netpart.puml[format=svg,id=030-etcd-netpart]

[.notes]
****
### Partition Réseau
- **Description** : Une partition réseau divise un cluster etcd en deux parties : une majorité et une minorité de membres.
- **Absence de "Split-brain"** : etcd évite le phénomène de "split-brain" car les membres du cluster sont explicitement ajoutés ou retirés avec l'approbation de la majorité actuelle.
- **Split brain** : quand deux membres sont leaders au même moment, créant un conflit dans les données écrites au moment de la synchro.

### Conséquences Selon la Position du Leader
- **Leader dans la Majorité** : Si le leader est du côté majoritaire, la défaillance est perçue comme une défaillance des followers minoritaires.
- **Leader dans la Minorité** : Si le leader est du côté minoritaire, il se retire, et un nouveau leader est élu par la majorité.

https://etcd.io/docs/v3.5/op-guide/failures/#network-partition
****

=== Défaillance pendant l’initialisation

[.notes]
****
Failure during bootstrapping : **redo**
https://etcd.io/docs/v3.5/op-guide/failures/#failure-during-bootstrapping
****

[.is-full.no-transition]
=== Recovery

// [.qrcode.five]
// qrcode::https://docs.rke2.io/datastore/backup_restore[format="png", xdim=4]
//
// [.qrcode.right.five]
// qrcode::https://etcd.io/docs/v3.5/op-guide/recovery/[format="png", xdim=4]

plantuml::diagrams/030-recovery-1.puml[format=svg,id=030-recovery-1]

[.notes]
****
Importance d'avoir des sauvegardes, et pas uniuqmenet sur le node !
****

[.is-full.no-transition]
=== Recovery

plantuml::diagrams/030-recovery-2.puml[format=svg,id=030-recovery-2]

[.notes]
****
Phase de nettoyage : on supprime les données de l'ETCD avant de le réintégrer dans le cluster, sinon, il ne pourra pas se réintégrer au quorum en tant que nouveau membre

****

[.is-full.no-transition]
=== Recovery

plantuml::diagrams/030-recovery-3.puml[format=svg,id=030-recovery-3]

[.notes]
****
Ensuite, on démarre un mono cluster à partir du snapshot
****

[.is-full.no-transition]
=== Recovery

plantuml::diagrams/030-recovery-4.puml[format=svg,id=030-recovery-4]

[.notes]
****
Ajout des autres nodes + vérification

Recovery : ETCD crash, comment on récupère ? Snapshot d'une dernière VM / soit backup ETCD (avec recréation d'un nouveau quorum mono et intégration des autres membres)

On précise que l'on doit supprimer les données de l'ETCD encore disponible avant de le réintégrer dans le cluster, sinon, il ne pourra pas se réintégrer au quorum en tant que nouveau membre
****

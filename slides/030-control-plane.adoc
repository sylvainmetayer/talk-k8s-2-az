[%auto-animate.is-full]
== Mono CP

[.column]
--
plantuml::diagrams/030-mono-cp.puml[format=svg,id=030-mono-cp]
--

[.notes]
****
mono CP. 1 control plane pour notre cluster, 1 vm CP sur un des 2 sites. Redondacne à la VMWare (VRA ??) snapshot de la VM, on remonte de l'autre côté

Présenter 3/0, sans parler d'ETCD RAFt, et besoin de CP sur les 2 côtés pour API haute dispo car opérateur qui met à jour services / pas de bascule auto VMWare car pas licence pour mon projet et aç créé problème supplémentaire, car mes opérateurs ne peuvent pas metre à jour les services / ...
****

[%auto-animate.is-full.columns]
== Multi CP

[.column.is-four-fifths]
--
plantuml::diagrams/030-multi-cp.puml[format=svg,id=030-multi-cp]
--

[.column]
--
image::openshift-logo.svg[width=100]
--


[.notes]
****
En théorie, la mécanique reste la même : on bascule nos 3 control planes sur la région B. On a donc 3 control planes sur la région B.

==> Attention, moi j'ai besoin d'avoir l'API dispo en continu, j'ai des opérateurs qui dépendent de l'API k8s !

Bon, bah on va faire du 2/1, ça doit être possible ? Qu'est-ce qu'il y a derrière ce fameux control plane qui nous en empêche de faire ça ? Voyons ça !
****

== Control Plane

[link=https://kubernetes.io/docs/concepts/overview/components/]
image::kubernetes-components.svg[]

[.notes]
****
TODO Schéma des composants d'un control plane, avec les différents composants (kube-apiserver, kube-controller-manager, kube-scheduler, etcd) et comment ils interagissent entre eux.

On va maintenant s'intéresser à la partie qui nécessite de la persistence de données, ETCD
****

[%notitle]
=== etcd

[link=https://etcd.io/]
image::images/etcd-horizontal-color.svg[]
image::images/etcd-xkcd-2347.webp[]

[.notes]
****
Base clé-valeurs distribuée, créé par CoreOS en 2013, puis passé dans le giron de la CNCF depuis 2018.
Composant du cœur de k8s
****

=== Raft consensus algorithm

[link=https://raft.github.io]
image::images/raft-sticker.svg

[.notes]
****
Algo de consensus implémenté dans etcd.
Illustration : raftscope (en JS) ou schéma ?
Sinon une note sur la mécanique et explication orale uniquement.
- algo pour implémenter la réplication de logs
- le système évolue/avance tant que la majorité des nœuds sont disponibles
- model d’erreur : fail-stop, delayed/lost messages
- conçu pour la compréhensibilité
****

=== Follower failure

[.notes]
****
https://etcd.io/docs/v3.5/op-guide/failures/#minor-followers-failure
****

=== Leader failure

[.notes]
****
https://etcd.io/docs/v3.5/op-guide/failures/#minor-followers-failure
****

=== Majority failure

[.notes]
****
https://etcd.io/docs/v3.5/op-guide/failures/#majority-failure
****

=== Network partition

[.notes]
****
https://etcd.io/docs/v3.5/op-guide/failures/#network-partition
****

=== Failure during bootstrapping

[.notes]
****
https://etcd.io/docs/v3.5/op-guide/failures/#failure-during-bootstrapping
****

== Recovery

- https://etcd.io/docs/v3.5/op-guide/recovery/
- https://docs.rke2.io/datastore/backup_restore#restoring-a-snapshot-to-new-nodes


[.notes]
****
Screenshot de crash election membre voir schéma RAFT.
Recovery : ETCD crash, comment on récupère ? Snapshot d'une dernière VM / soit backup ETCD (avec recréation d'un nouveau quorum mono et intégration des autres membres) => Schéma !
****
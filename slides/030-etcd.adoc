[%notitle]
== etcd

[link=https://etcd.io/]
image::etcd-horizontal-color.svg[]

image::etcd-xkcd-2347.webp[]

[.notes]
****
Base clé-valeurs distribuée, créé par CoreOS en 2013, puis passé dans le giron de la CNCF depuis 2018.
Composant du cœur de k8s
****

=== Raft consensus algorithm

[link=https://raft.github.io]
image::raft-sticker.svg[]

[.notes]
****
TODO Ajout légende = faut que ça figure sur l'aspect election (N/2+1) = slide qu'est-ce que l'élection ? Speaker notes à revoir > légende des données committées / en attente d'écriture (index.html à revoir)

Algo de consensus implémenté dans etcd.

Sinon une note sur la mécanique et explication orale uniquement.
- algo pour implémenter la réplication de logs
- le système évolue/avance tant que la majorité des nœuds sont disponibles
- model d’erreur : fail-stop, delayed/lost messages
- conçu pour la compréhensibilité
****

=== Raft - Consensus

[.notes]
****
TOOD

raft = consensus insister dessus qu'est-ce que c'est

Schéma ?
****

[%notitle,background-iframe="{raftscope_url}"]
=== Démo

[.notes]
****
https://github.com/ongardie/raftscope.git

scénario :
1. Dès qu’un leader est élu, Request pour écrire
2. Stop follower
3. Request
4. Time out pour lancer une nouvelle élection sur follower, puis Request
5. Stop leader - pas d’élection possible
6. Resume followers
7. Request, et Stop leader avant consensus
8. Time out sur un follower, dès élection Request
9. Retour de l’ancien leader : il se met à jour
****

=== Network partition

plantuml::diagrams/030-etcd-netpart.puml[format=svg,id=030-etcd-netpart]

[.notes]
****
### Partition Réseau
- **Description** : Une partition réseau divise un cluster etcd en deux parties : une majorité et une minorité de membres.
- **Absence de "Split-brain"** : etcd évite le phénomène de "split-brain" car les membres du cluster sont explicitement ajoutés ou retirés avec l'approbation de la majorité actuelle.
- **Split brain** : quand deux membres sont leaders au même moment, créant un conflit dans les données écrites au moment de la synchro.

### Conséquences Selon la Position du Leader
- **Leader dans la Majorité** : Si le leader est du côté majoritaire, la défaillance est perçue comme une défaillance des followers minoritaires.
- **Leader dans la Minorité** : Si le leader est du côté minoritaire, il se retire, et un nouveau leader est élu par la majorité.

https://etcd.io/docs/v3.5/op-guide/failures/#network-partition

TODO contraintes partition / réseau / tabeau avantage/inconvénietn rapide // Corriger le schéma !
****

=== Défaillance pendant l’initialisation

[.notes]
****
Failure during bootstrapping : **redo**
https://etcd.io/docs/v3.5/op-guide/failures/#failure-during-bootstrapping
****

[.is-full.no-transition]
=== Recovery

plantuml::diagrams/030-recovery-1.puml[format=svg,id=030-recovery-1]

[.notes]
****
Importance d'avoir des sauvegardes, et pas uniquement sur le node !
****

[.is-full.no-transition]
=== Recovery

plantuml::diagrams/030-recovery-2.puml[format=svg,id=030-recovery-2]

[.notes]
****
Phase de nettoyage : on supprime les données de l'ETCD avant de le réintégrer dans le cluster, sinon, il ne pourra pas se réintégrer au quorum en tant que nouveau membre

****

[.is-full.no-transition]
=== Recovery

plantuml::diagrams/030-recovery-3.puml[format=svg,id=030-recovery-3]

[.notes]
****
Ensuite, on démarre un mono cluster à partir du snapshot
****

[.is-full.no-transition]
=== Recovery

plantuml::diagrams/030-recovery-4.puml[format=svg,id=030-recovery-4]

[.notes]
****
Ajout des autres nodes + vérification

Recovery : ETCD crash, comment on récupère ? Snapshot d'une dernière VM / soit backup ETCD (avec recréation d'un nouveau quorum mono et intégration des autres membres)

On précise que l'on doit supprimer les données de l'ETCD encore disponible avant de le réintégrer dans le cluster, sinon, il ne pourra pas se réintégrer au quorum en tant que nouveau membre
****
